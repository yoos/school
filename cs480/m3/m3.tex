\documentclass[12pt,letterpaper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}
\usepackage[utf8]{inputenc}
\usepackage{palatino}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{lastpage}
\usepackage[hang,small,margin=1in]{caption}
\usepackage{titlesec}
\usepackage{pdfpages}

\renewcommand{\headrulewidth}{0pt}
\fancyfoot{}
\fancyfoot[C]{\sffamily Page \thepage\ of \pageref{LastPage}}
\pagestyle{fancy}

\titleformat{\section}{\bfseries\MakeUppercase}{\arabic{\thesection}}{1em}{}
\titleformat{\subsection}{\bfseries}{\arabic{\thesection}.\arabic{\thesubsection}}{1em}{}
\titleformat{\subsubsection}{\itshape}{\arabic{\thesection}.\arabic{\thesubsection}.\arabic{\thesubsubsection}}{1em}{}

\setlength{\parindent}{0cm}
\setlength{\parskip}{1em}

\captionsetup[figure]{labelfont=it, font=it}
\captionsetup[table]{labelfont={it,sc}, font={it,sc}}

\hypersetup{colorlinks, linkcolor = black, citecolor = black, urlcolor = black}
\urlstyle{same}



\begin{document}

\fancyfoot{}
\begin{center}
    \hfill \\
    \vspace{4in}
    {\bf\Huge CS480 Milestone \#3 \\}
    \vspace{2in}
    {\Large Soo-Hyun Yoo \\ February 16, 2015}
\end{center}

\newpage
\fancyfoot[C]{\sffamily Page \thepage\ of \pageref{LastPage}}

% Handwritten answers
%\includepdf[pages={1}]{m3_handwritten.pdf}

\section*{Formal Definition}

\subsection*{Parser}

\begin{verbatim}
def check-syntax(input):
    stack = [S]
    while (input != [] and stack != []):
        rule, term = stack.pop_front(), input.pop_front()
        if (rule == term): continue
        p = productions[rule][term]
        if p = DNE: return FALSE
        stack.push_front(p[1:])
    if (input != [] or stack != []):
        return FALSE
    return TRUE
\end{verbatim}

\section*{Specification}

This milestone prompts me to pick a data structure to represent the syntax
graphs that will be used to determine whether or not the list of symbols
satisfy the IBTL syntax. I will develop an algorithm to recursively parse these
syntax trees. In doing so, I will also find out whether the symbol table
structure is sufficient for the tasks at hand or needs improvement.

\section*{Processing}

All token types were recategorized as lists of types and type symbols. These
were used to specify the production rules of the IBTL grammar.

The provided grammar was refactored to more closely mirror the lexer before
being incorporated into the definition in code. The compiler passes this
definition to the syntax parser along with the symbol table output from the
lexer and an initial recursion depth of 0.

\section*{Testing Requirement}

I tested the parser for correctness by using inputs similar to those used in
Milestone 2 to test the lexer. The inputs are composed of as many combinations
of token types as I could reasonably come up with along with some nested
parentheses. The tokens are output at an indentation proportional to the
recursion depth, which was checked manually.

\section*{Retrospective}

The symbol table and lexer did not require heavy modification. I can see
(again) that having a clear model and modular code is paramount to keeping the
compiler comprehensible.

Lisp has various list manipulation tools built into the language that makes it
easy to move data around. I have not yet fully grasped the different symbol and
value types specified by Lisp's modifiers, but I have been able to use a few to
make the code more concise (e.g., list element expansion to populate list of
terminals from list of list of terminal types in {\tt grammar.lisp}).

\end{document}
